{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41bddf10-0091-4e81-a0bd-432dd45e019e",
   "metadata": {},
   "source": [
    "# EpiBERT Data Processing Workflow\n",
    "\n",
    "This notebook demonstrates the complete data processing pipeline for preparing input data for EpiBERT analysis. \n",
    "\n",
    "## Overview\n",
    "\n",
    "EpiBERT requires two main types of input data:\n",
    "\n",
    "1. **Motif enrichment file**: Generated using Simple Enrichment Analysis (SEA) from the MEME suite\n",
    "2. **Processed ATAC-seq data**: Fragment end positions in bedgraph format\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before running this workflow, ensure you have the following tools installed:\n",
    "\n",
    "- **bedtools**: For genomic interval operations\n",
    "- **samtools**: For BAM file processing  \n",
    "- **MEME suite**: For motif enrichment analysis\n",
    "- **tabix**: For indexing compressed files\n",
    "\n",
    "## Data Requirements\n",
    "\n",
    "- **Peak calls**: ATAC-seq peaks in BED format (e.g., from ENCODE)\n",
    "- **BAM files**: Aligned ATAC-seq reads\n",
    "- **Reference genome**: hg38 FASTA file with index\n",
    "- **Motif database**: Consensus PWMs for transcription factors\n",
    "\n",
    "Let's walk through each step of the processing pipeline.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0c637a-2773-4901-aea2-5b6c11e05b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 1: Download Example ATAC-seq Peaks\n",
    "\n",
    "We'll use K562 ATAC-seq peaks from ENCODE as an example dataset. These are IDR-thresholded peaks representing high-confidence chromatin accessibility regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download K562 ATAC-seq peaks from ENCODE\n",
    "# File: ENCFF135AEX - K562 IDR thresholded peaks\n",
    "wget -q https://www.encodeproject.org/files/ENCFF135AEX/@@download/ENCFF135AEX.bed.gz\n",
    "\n",
    "echo \"✓ Downloaded ATAC-seq peaks file\"\n",
    "ls -lh ENCFF135AEX.bed.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63448ede-b6ae-46e6-8a42-466f9aec03be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 2: Prepare Reference Genome\n",
    "\n",
    "Ensure you have the hg38 reference genome FASTA file downloaded and indexed. You can download it from ENCODE: https://www.encodeproject.org/references/ENCSR938RZZ/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index the reference genome FASTA file\n",
    "# This creates a .fai index file needed for bedtools getfasta\n",
    "samtools faidx hg38_erccpatch.fa\n",
    "\n",
    "echo \"✓ Reference genome indexed\"\n",
    "ls -lh hg38_erccpatch.fa*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c982e6c3-a13e-411b-b050-d30cb46d27b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sort: write failed: 'standard output': Broken pipe\n",
      "sort: write error\n"
     ]
    }
   ],
   "source": [
    "## Step 3: Extract Peak Sequences for Motif Analysis\n",
    "\n",
    "Now we'll extract sequences from the top peaks for motif enrichment analysis. We take the top 50,000 peaks by signal and extract 128bp around each peak center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract top 50,000 peaks and get 128bp around peak centers\n",
    "# Sort by signal value (column 5), take top peaks, extract peak center ± 64bp\n",
    "zcat ENCFF135AEX.bed.gz | \\\n",
    "  sort -k5,5nr | \\\n",
    "  head -n 50000 | \\\n",
    "  awk '{OFS = \"\\t\"}{print $1,$2+$10-64,$2+$10+64}' | \\\n",
    "  sort -k1,1 -k2,2n > ENCFF135AEX.sorted.peaks.bed\n",
    "\n",
    "echo \"✓ Extracted peak regions\"\n",
    "wc -l ENCFF135AEX.sorted.peaks.bed\n",
    "\n",
    "# Extract sequences for foreground (peaks of interest)\n",
    "bedtools getfasta -fi hg38_erccpatch.fa -bed ENCFF135AEX.sorted.peaks.bed > ENCFF135AEX.peaks.fasta\n",
    "\n",
    "# Extract sequences for background (using provided background peaks)\n",
    "bedtools getfasta -fi hg38_erccpatch.fa -bed all_peaks_merged.counts.shared.centered.bed > bg_peaks.fasta\n",
    "\n",
    "echo \"✓ Extracted FASTA sequences\"\n",
    "ls -lh *.fasta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd19d22-6dfe-43cd-aa36-943e4dbfb2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 4: Run Motif Enrichment Analysis\n",
    "\n",
    "Run Simple Enrichment Analysis (SEA) from MEME using consensus PWMs. We use the 693 consensus PWMs from Vierstra et al. (https://resources.altius.org/~jvierstra/projects/motif-clustering-v2.0beta/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Simple Enrichment Analysis (SEA) from MEME\n",
    "# Parameters:\n",
    "# --p: positive sequences (peaks of interest)\n",
    "# --m: motif database (consensus PWMs)\n",
    "# --n: negative/background sequences  \n",
    "# --thresh: significance threshold\n",
    "# --verbosity: output level\n",
    "\n",
    "/home/jupyter/meme-5.5.6/src/sea \\\n",
    "  --p ENCFF135AEX.peaks.fasta \\\n",
    "  --m consensus_pwms.meme \\\n",
    "  --n bg_peaks.fasta \\\n",
    "  --thresh 50000.0 \\\n",
    "  --verbosity 1\n",
    "\n",
    "# Move the output file to a more descriptive name\n",
    "mv sea_out/sea.tsv ENCFF135AEX.motifs.tsv\n",
    "\n",
    "echo \"✓ Motif enrichment analysis completed\"\n",
    "ls -lh ENCFF135AEX.motifs.tsv\n",
    "head -5 ENCFF135AEX.motifs.tsv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d73b97-e386-4add-b29d-b488d784d4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 5: Prepare ATAC-seq BAM File\n",
    "\n",
    "Next, we'll process the ATAC-seq BAM file to extract fragment end positions. You can download the processed BAM file from ENCODE for K562: https://www.encodeproject.org/files/ENCFF534DCE/@@download/ENCFF534DCE.bam\n",
    "\n",
    "**Note**: This is a large file (~20GB). Make sure you have sufficient disk space and bandwidth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81be3699-6291-42d5-b3f4-434f7e953ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 6: Process BAM to Extract Fragment Ends\n",
    "\n",
    "Convert the BAM file to extract ATAC-seq fragment end positions with proper Tn5 adjustments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, sort the BAM file by read name (required for bedpe output)\n",
    "# Uncomment the line below if you need to sort your BAM file\n",
    "# samtools sort -n ENCFF534DCE.bam -o ENCFF534DCE.sorted.bam\n",
    "\n",
    "# Extract fragment ends with Tn5 adjustments\n",
    "# Steps:\n",
    "# 1. Convert BAM to BEDPE format\n",
    "# 2. Filter for proper pairs (same chromosome)\n",
    "# 3. Filter for fragments >= 20bp\n",
    "# 4. Apply Tn5 adjustments (+4bp for 5' end, -5bp for 3' end)\n",
    "# 5. Ensure start < end coordinates\n",
    "# 6. Sort and compress\n",
    "\n",
    "bedtools bamtobed -i ENCFF534DCE.sorted.bam -bedpe | \\\n",
    "  awk '$1 == $4' | \\\n",
    "  awk '$8 >= 20' | \\\n",
    "  awk -v OFS=\"\\t\" '{if($9 == \"+\"){print $1,$2+4,$6-5}else if($9==\"-\"){print $1,$5+4,$3-5}}' | \\\n",
    "  awk -v OFS=\"\\t\" '{if($3<$2){print $1,$3,$2}else if($3>$2){print $1,$2,$3}}' | \\\n",
    "  awk '$3-$2 > 0' | \\\n",
    "  sort -k1,1 -k2,2n | gzip > K562.bed.gz\n",
    "\n",
    "echo \"✓ Fragment ends extracted\"\n",
    "\n",
    "# Calculate scale factor (fragments per million)\n",
    "zcat K562.bed.gz | wc -l | awk '{ print $1 / 1000000.0 }' > K562.num_fragments.out\n",
    "\n",
    "echo \"✓ Scale factor calculated:\"\n",
    "cat K562.num_fragments.out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7aed86-7f08-46dd-a780-6e6275ff7a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 7: Create Bedgraph Signal Track\n",
    "\n",
    "Convert fragment ends to a bedgraph signal track representing chromatin accessibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate files for forward and reverse strand cut sites\n",
    "zcat K562.bed.gz | awk '{OFS=\"\\t\"}{print $1,$2+4,$2+4+1}' | gzip > fwd.bed.gz\n",
    "zcat K562.bed.gz | awk '{OFS=\"\\t\"}{print $1,$3-5,$3-5+1}' | gzip > rev.bed.gz\n",
    "\n",
    "# Combine forward and reverse strand cut sites\n",
    "zcat fwd.bed.gz rev.bed.gz | sort -k1,1 -k2,2n > HG_K562.bed.temp\n",
    "\n",
    "echo \"✓ Cut sites extracted for both strands\"\n",
    "\n",
    "# Create bedgraph with proper scaling\n",
    "# Steps:\n",
    "# 1. Extend each cut site by ±5bp (10bp total window)\n",
    "# 2. Filter out non-standard chromosomes\n",
    "# 3. Remove negative coordinates\n",
    "# 4. Scale to reads per 20 million (scale factor: 20/111.279 = 0.1797)\n",
    "# 5. Generate bedgraph coverage\n",
    "\n",
    "cat HG_K562.bed.temp | \\\n",
    "  awk '{OFS=\"\\t\"}{print $1,$2-5,$3+5}' | \\\n",
    "  grep -v 'KI\\|GL\\|EBV\\|chrM\\|chrMT\\|K\\|J' | \\\n",
    "  awk '$2 >= 0' | \\\n",
    "  sort -k1,1 -k2,2n | \\\n",
    "  bedtools genomecov -i - -g hg38.genome -scale 0.1797 -bg | \\\n",
    "  sort -k1,1 -k2,2n > K562.bedgraph\n",
    "\n",
    "echo \"✓ Bedgraph created\"\n",
    "\n",
    "# Rename and compress for tabix indexing\n",
    "mv K562.bedgraph K562.adjust.bed\n",
    "bgzip K562.adjust.bed\n",
    "tabix K562.adjust.bed.gz\n",
    "\n",
    "echo \"✓ Final processed file created: K562.adjust.bed.gz\"\n",
    "ls -lh K562.adjust.bed.gz*\n",
    "\n",
    "# Clean up intermediate files\n",
    "rm -f fwd.bed.gz rev.bed.gz HG_K562.bed.temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1858b49-e34f-41c1-b0ac-0bfdd12d0d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates the complete data processing pipeline for EpiBERT:\n",
    "\n",
    "### Output Files Generated:\n",
    "\n",
    "1. **ENCFF135AEX.motifs.tsv** - Motif enrichment scores for input to EpiBERT\n",
    "2. **K562.adjust.bed.gz** - Processed ATAC-seq signal track for input to EpiBERT\n",
    "\n",
    "### Key Processing Steps:\n",
    "\n",
    "1. **Peak Selection**: Extract top 50K peaks by signal strength\n",
    "2. **Sequence Extraction**: Get 128bp regions around peak centers\n",
    "3. **Motif Analysis**: Run SEA to identify enriched transcription factor motifs\n",
    "4. **Fragment Processing**: Extract ATAC-seq fragment ends with Tn5 corrections\n",
    "5. **Signal Generation**: Create normalized bedgraph tracks for accessibility\n",
    "\n",
    "### Usage in EpiBERT:\n",
    "\n",
    "These processed files can now be used as inputs for EpiBERT analysis:\n",
    "- The motif file provides transcription factor binding context\n",
    "- The bedgraph file provides chromatin accessibility signal\n",
    "- Together they enable prediction of variant effects on accessibility\n",
    "\n",
    "### Quality Control:\n",
    "\n",
    "- Verify motif enrichment results show expected TF families\n",
    "- Check bedgraph signal correlates with known accessible regions\n",
    "- Ensure file formats are compatible with EpiBERT input requirements\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. Use these files in the `caqTL_predict.ipynb` notebook\n",
    "2. Adapt the pipeline for your own cell type and experimental data\n",
    "3. Experiment with different peak selection criteria or motif databases\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m128"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
