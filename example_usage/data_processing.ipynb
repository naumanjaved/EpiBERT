{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41bddf10-0091-4e81-a0bd-432dd45e019e",
   "metadata": {},
   "source": [
    "# EpiBERT Data Processing Workflow\n",
    "\n",
    "This notebook demonstrates preparing input data for EpiBERT analysis.\n",
    "\n",
    "## Overview\n",
    "\n",
    "We require two main types of input data:\n",
    "\n",
    "1. Motif enrichment file: Generated using Simple Enrichment Analysis (SEA) from the MEME suite\n",
    "2.  ATAC-seq data: Fragment end positions in bedgraph format\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before running this workflow, ensure you have the following tools installed:\n",
    "\n",
    "### System Requirements\n",
    "- Python 3.8+ with EpiBERT dependencies (see `requirements.txt`)\n",
    "- bedtools v2.30+: For genomic interval operations\n",
    "- samtools v1.15+: For BAM file processing  \n",
    "- MEME suite v5.4+: For motif enrichment analysis\n",
    "-*tabix: For indexing compressed files\n",
    "\n",
    "## Data Requirements\n",
    "\n",
    "- Peak calls ATAC-seq peaks in BED format (e.g., from ENCODE)\n",
    "- BAM files Aligned ATAC-seq reads\n",
    "- Reference genome hg38 FASTA file with index\n",
    "- Motif database Consensus PWMs for transcription factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0c637a-2773-4901-aea2-5b6c11e05b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 1: Download Example ATAC-seq Peaks\n",
    "\n",
    "# Use K562 IDR thresholded ATAC-seq peaks from ENCODE as an example dataset. \n",
    "\n",
    "# Download K562 ATAC-seq peaks from ENCODE\n",
    "# File: ENCFF135AEX - K562 IDR thresholded peaks\n",
    "!wget -q https://www.encodeproject.org/files/ENCFF135AEX/@@download/ENCFF135AEX.bed.gz\n",
    "\n",
    "## Step 2: Prepare Reference Genome\n",
    "\n",
    "#Ensure you have the hg38 reference genome FASTA file downloaded and indexed. You can download it from ENCODE: https://www.encodeproject.org/references/ENCSR938RZZ/\n",
    "\n",
    "# Index the reference genome FASTA file\n",
    "# This creates a .fai index file needed for bedtools getfasta\n",
    "!wget -O hg38_erccapatch.fa.gz ftp://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/hg38.fa.gz\n",
    "!gzip -d hg38_erccapatch.fa.gz\n",
    "!samtools faidx hg38_erccpatch.fa\n",
    "\n",
    "## Step 3: Extract Peak Sequences for Motif Analysis\n",
    "\n",
    "# Extract top 50,000 peaks and get 128bp around peak centers\n",
    "# Sort by signal value (column 5), take top peaks, extract peak center Â± 64bp\n",
    "zcat ENCFF135AEX.bed.gz | \\\n",
    "  sort -k5,5nr | \\\n",
    "  head -n 50000 | \\\n",
    "  awk '{OFS = \"\\t\"}{print $1,$2+$10-64,$2+$10+64}' | \\\n",
    "  sort -k1,1 -k2,2n > ENCFF135AEX.sorted.peaks.bed\n",
    "\n",
    "!wc -l ENCFF135AEX.sorted.peaks.bed\n",
    "\n",
    "!bedtools getfasta -fi hg38_erccpatch.fa -bed ENCFF135AEX.sorted.peaks.bed > ENCFF135AEX.peaks.fasta # Extract sequences for foreground (peaks of interest)\n",
    "!bedtools getfasta -fi hg38_erccpatch.fa -bed all_peaks_merged.counts.shared.centered.bed > bg_peaks.fasta # Extract sequences for background (using provided background peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd19d22-6dfe-43cd-aa36-943e4dbfb2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 4: Run Motif Enrichment Analysis\n",
    "\n",
    "# Run Simple Enrichment Analysis (SEA) from MEME using consensus PWMs. We use the 693 consensus PWMs from Vierstra et al. (https://resources.altius.org/~jvierstra/projects/motif-clustering-v2.0beta/)\n",
    "\n",
    "# Run Simple Enrichment Analysis (SEA) from MEME\n",
    "# Parameters:\n",
    "# --p: positive sequences (peaks of interest)\n",
    "# --m: motif database (consensus PWMs)\n",
    "# --n: negative/background sequences  \n",
    "# --thresh: significance threshold\n",
    "# --verbosity: output level\n",
    "\n",
    "/insertpathtomemesuiteinstallation/meme-5.5.6/src/sea \\\n",
    "  --p ENCFF135AEX.peaks.fasta \\\n",
    "  --m consensus_pwms.meme \\\n",
    "  --n bg_peaks.fasta \\\n",
    "  --thresh 50000.0 \\\n",
    "  --verbosity 1\n",
    "\n",
    "# Move the output file to a more descriptive na\n",
    "!v sea_out/sea.tsv ENCFF135AEX.motifs.tsv\n",
    "head -5 ENCFF135AEX.motifs.tsv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d73b97-e386-4add-b29d-b488d784d4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 5/6: Process ATAC-seq BAM File\n",
    "\n",
    "# Next process the ATAC-seq BAM file to extract fragment end positions w/ Tn5 adjustmenets. You can download the processed BAM file from ENCODE for K562: https://www.encodeproject.org/files/ENCFF534DCE/@@download/ENCFF534DCE.bam\n",
    "# **Note**: This is a large file (~20GB). Make sure you have sufficient disk space and bandwidth.\n",
    "\n",
    "# Srt the BAM file by read name (required for bedpe output)\n",
    "# Uncomment the line below if you need to sort your BAM file\n",
    "# samtools sort -n ENCFF534DCE.bam -o ENCFF534DCE.sorted.bam\n",
    "\n",
    "# Extract fragment ends with Tn5 adjustments\n",
    "# Steps:\n",
    "# 1. Convert BAM to BEDPE format\n",
    "# 2. Filter for proper pairs (same chromosome)\n",
    "# 3. Filter for fragments >= 20bp\n",
    "# 4. Apply Tn5 adjustments (+4bp for 5' end, -5bp for 3' end)\n",
    "# 5. Ensure start < end coordinates\n",
    "# 6. Sort and compress\n",
    "\n",
    "# first we sort the bam\n",
    "#!samtools sort -n ENCFF534DCE.bam -o ENCFF534DCE.sorted.bam\n",
    "# then for each pair extract the 5 and 3' cut sites and make the required Tn5 adjustmenet\n",
    "!bedtools bamtobed -i ENCFF534DCE.sorted.bam -bedpe | \\\n",
    "        awk '$1 == $4' | \\\n",
    "        awk '$8 >= 20' | \\\n",
    "        awk -v OFS=\"\\t\" '{if($9 == \"+\"){print $1,$2+4,$6-5}else if($9==\"-\"){print $1,$5+4,$3-5}}' | \\\n",
    "        awk -v OFS=\"\\t\" '{if($3<$2){print $1,$3,$2}else if($3>$2){print $1,$2,$3}}' | \\\n",
    "        awk '$3-$2 > 0' | \\\n",
    "        sort -k1,1 -k2,2n | gzip > K562.bed.gz\n",
    "\n",
    "\n",
    "## get scale factor which is 111.279\n",
    "!zcat K562.bed.gz | wc -l | awk '{ print $1 / 1000000.0 }' > K562.num_fragments.out\n",
    "\n",
    "# Create separate files for forward and reverse strand cut sites\n",
    "zcat K562.bed.gz | awk '{OFS=\"\\t\"}{print $1,$2,$2+1}' | gzip > fwd.bed.gz\n",
    "zcat K562.bed.gz | awk '{OFS=\"\\t\"}{print $1,$3,$3+1}' | gzip > rev.bed.gz\n",
    "\n",
    "# Combine forward and reverse strand cut sites\n",
    "zcat fwd.bed.gz rev.bed.gz | sort -k1,1 -k2,2n > HG_K562.bed.temp\n",
    "\n",
    "# turn into bedgraph (get 10bp around each insertion site, then scale to reads per 20 million -> 20/ 111.279  = 0.1797\n",
    "# make sure you provide a genome file for bedtools genomcov \n",
    "!cat HG_K562.bed.temp | awk '{ OFS=\"\\t\" } {print $1,$2-5,$3+5}' | \\\n",
    "                    grep -v 'KI\\|GL\\|EBV\\|chrM\\|chrMT\\|K\\|J' | \\\n",
    "                    awk '$2 >= 0' | sort -k1,1 -k2,2n | \\\n",
    "                    bedtools genomecov -i - -g hg38.genome -scale 0.1797 -bg | sort -k1,1 -k2,2n > K562.bedgraph\n",
    "\n",
    "!mv K562.bedgraph K562.adjust.bed # rename since tabix will throw an error if bedgraph named \n",
    "!bgzip K562.adjust.bed # bgzip for tabix \n",
    "!tabix K562.adjust.bed.gz # tabix index\n",
    "\n",
    "# Clean up intermediate files\n",
    "rm -f fwd.bed.gz rev.bed.gz HG_K562.bed.temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9f4261",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m128"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
